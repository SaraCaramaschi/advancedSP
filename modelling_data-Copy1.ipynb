{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Modelling data\n",
    "# Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(\"df_1.csv\", sep=\",\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df['In-hospital_death'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Downsampling\n",
    "# separare in righe per target\n",
    "t0=df[df['In-hospital_death']==0]\n",
    "t1=df[df['In-hospital_death']==1]\n",
    "print(\"t0 e t1: \", len(t0), len(t1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "t0_down = resample(t0, replace=True, n_samples=591, random_state=123)\n",
    "print(\"t0 down: \", len(t0_down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([t0_down, t1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "#TROVARE MODO DI PESARE IL TARGET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "y=df['In-hospital_death']\n",
    "x= df.drop(['In-hospital_death'], axis=1)\n",
    "X_train, X_test, y_train, y_test=train_test_split(x, y, test_size=0.3, stratify=y, random_state=123)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hyperp_search(classifier, parameters):\n",
    "    gs = GridSearchCV(classifier, parameters, cv=5, scoring = 'f1', verbose=0, n_jobs=-1)\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    print(\"f1_train: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "\n",
    "    best_model = gs.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(\"f1_test: \", f1_score(y_test, y_pred), \"\\n\\n\")\n",
    "    print(confusion_matrix(y_test, y_pred), \"\\n\\n\")\n",
    "    print(classification_report(y_test, y_pred), \"\\n\\n\")\n",
    "\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(recall, precision, color='purple')\n",
    "\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xlabel('Recall')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def roc(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds1 = metrics.roc_curve(y_test, y_probs[:, 1])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(fpr, tpr, label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('FP Rate')\n",
    "    plt.ylabel('TP Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test, y_probs[:, 1])\n",
    "    print('AUC: %.2f' % auc)\n",
    "    return (fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':np.arange(10,100, 1000)}\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "fpr1, tpr1 = roc(model_knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "parameters = {'criterion': ['entropy','gini'], 'max_depth': [4,5,10], 'min_samples_split': [20],'min_samples_leaf': [10], 'class_weight':['balanced']}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=10, min_samples_split=20)\n",
    "\n",
    "fpr2,tpr2=roc(model_tree,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB #or alternative NB implementations\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1_score: \", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"f1_test: \", f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(X_test) #predict_proba gives the probabilities for the target (0 and 1 in your case)\n",
    "\n",
    "fpr3,tpr3=roc(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "parameters = {\"C\":[1e-4,1e-3,1e-2,1e-1,1,10], \"max_iter\":[1000], 'class_weight':['balanced']}\n",
    "\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.0001, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "fpr4,tpr4=roc(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {\"kernel\":['linear', 'rbf'], \"C\":[0.1, 1], \"class_weight\":['balanced']}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = SVC(C=0.1, kernel='rbf',probability=True, class_weight='balanced')\n",
    "\n",
    "fpr5,tpr5=roc(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron classifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "parameters = {\"hidden_layer_sizes\":[(10, 5),(20,5)],  \"max_iter\": [1000], \"alpha\": [0.001,0.1]}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_MLP=MLPClassifier(hidden_layer_sizes=(20,5), alpha=0.1, max_iter=1000)\n",
    "\n",
    "fpr6,tpr6=roc(model_MLP,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(n_estimators=50, random_state=123)\n",
    "parameters={'criterion': ['entropy','gini'], 'max_depth': [4,5,10], 'min_samples_leaf': [5, 10],'min_samples_split': [5, 10]}\n",
    "\n",
    "def hyperp_search(classifier, parameters):\n",
    "    gs=GridSearchCV(classifier, parameters, cv=3, scoring = 'f1', verbose=0, n_jobs=-1)\n",
    "    gs=gs.fit(X_train, y_train)\n",
    "    print(\"f1_train: %f using %s\" %(gs.best_score_, gs.best_params_))\n",
    "\n",
    "    best_model=gs.best_estimator_\n",
    "    y_pred=best_model.predict(X_test)\n",
    "\n",
    "    print(\"f1_test: \", f1_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_RF=RandomForestClassifier(criterion='gini', max_depth=10, min_samples_leaf=5, min_samples_split=5)\n",
    "\n",
    "fpr7,tpr7=roc(model_RF,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr1, tpr1, label= \"KNN\")\n",
    "plt.plot(fpr2, tpr2, label= \"Tree\")\n",
    "plt.plot(fpr3, tpr3, label= \"NB\")\n",
    "plt.plot(fpr4, tpr4, label= \"Logistic\")\n",
    "plt.plot(fpr5, tpr5, label= \"SVM\")\n",
    "plt.plot(fpr6, tpr6, label= \"NeuralNet\")\n",
    "plt.plot(fpr7, tpr7, label= \"Random Forest\")\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Neural network - ok ma si pu√≤ migliorare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train_tuner, X_val_tuner, y_train_tuner, y_val_tuner = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=123)\n",
    "\n",
    "print(X_train_tuner.shape, X_val_tuner.shape)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes=2\n",
    "y_train_tuner_cat = to_categorical(y_train_tuner, num_classes)\n",
    "y_val_tuner_cat = to_categorical(y_val_tuner, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "y_train_tuner_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sequential model \n",
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "   # model.add(layers.Input(None, 39))\n",
    "    # model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=128, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(2, activation=\"sigmoid\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuner.search(X_train_tuner, y_train_tuner_cat, epochs=10, validation_data=(X_val_tuner, y_val_tuner_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 39))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((X_train_tuner, X_val_tuner))\n",
    "y_all = np.concatenate((y_train_tuner_cat, y_val_tuner_cat))\n",
    "\n",
    "x_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = build_model(best_hps[0])\n",
    "\n",
    "#mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "history= model.fit(x=x_all, y=y_all, validation_split=0.33, epochs=300, batch_size=50, callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "max_y_pred = np.argmax(y_pred, axis=1)\n",
    "max_y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, max_y_pred))\n",
    "print(\"Precision: \", precision_score(y_test,max_y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, max_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conmat = confusion_matrix(y_test, max_y_pred)\n",
    "val = np.mat(conmat) \n",
    "\n",
    "classnames = ['alive','dead']\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "        val, index=classnames, columns=classnames, \n",
    "    )\n",
    "\n",
    "print(df_cm)\n",
    "\n",
    "plt.figure()\n",
    "heatmap = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, max_y_pred)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}