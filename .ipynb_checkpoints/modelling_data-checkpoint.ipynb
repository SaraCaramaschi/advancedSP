{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAPS-I</th>\n",
       "      <th>Creatinine_last_log</th>\n",
       "      <th>BUN_last_log</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Na_last</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NIMAP_first</th>\n",
       "      <th>NIMAP_last</th>\n",
       "      <th>Weight_last</th>\n",
       "      <th>...</th>\n",
       "      <th>SysABP_diff</th>\n",
       "      <th>DiasABP_diff</th>\n",
       "      <th>FiO2_diff</th>\n",
       "      <th>Lactate_diff</th>\n",
       "      <th>In-hospital_death</th>\n",
       "      <th>CCU</th>\n",
       "      <th>CSRU</th>\n",
       "      <th>SICU</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MechVentLast8Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300668</td>\n",
       "      <td>0.333993</td>\n",
       "      <td>0.085820</td>\n",
       "      <td>0.391428</td>\n",
       "      <td>0.654019</td>\n",
       "      <td>-0.902033</td>\n",
       "      <td>-0.237425</td>\n",
       "      <td>-1.825970</td>\n",
       "      <td>-6.141845e-01</td>\n",
       "      <td>-0.156409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032026</td>\n",
       "      <td>1.106864</td>\n",
       "      <td>1.397652</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.122315</td>\n",
       "      <td>-1.948867</td>\n",
       "      <td>-2.668222</td>\n",
       "      <td>1.101179</td>\n",
       "      <td>-1.176765</td>\n",
       "      <td>-0.204228</td>\n",
       "      <td>-1.096743</td>\n",
       "      <td>1.260974</td>\n",
       "      <td>1.826724e+00</td>\n",
       "      <td>-1.396883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834433</td>\n",
       "      <td>0.736089</td>\n",
       "      <td>1.397652</td>\n",
       "      <td>-1.764760e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.027991</td>\n",
       "      <td>-0.629755</td>\n",
       "      <td>-0.299047</td>\n",
       "      <td>1.101179</td>\n",
       "      <td>-0.032525</td>\n",
       "      <td>-0.669431</td>\n",
       "      <td>1.454497</td>\n",
       "      <td>1.382102</td>\n",
       "      <td>-1.083075e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.318884</td>\n",
       "      <td>0.958554</td>\n",
       "      <td>-0.781002</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.793656</td>\n",
       "      <td>-0.869744</td>\n",
       "      <td>1.523650</td>\n",
       "      <td>0.391428</td>\n",
       "      <td>0.768443</td>\n",
       "      <td>-0.436830</td>\n",
       "      <td>-1.466295</td>\n",
       "      <td>-0.735819</td>\n",
       "      <td>-1.927924e+00</td>\n",
       "      <td>-1.810374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.970982</td>\n",
       "      <td>1.032709</td>\n",
       "      <td>1.397652</td>\n",
       "      <td>-7.463250e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027991</td>\n",
       "      <td>0.333993</td>\n",
       "      <td>0.151660</td>\n",
       "      <td>-0.081740</td>\n",
       "      <td>0.539595</td>\n",
       "      <td>0.028374</td>\n",
       "      <td>-0.678215</td>\n",
       "      <td>0.193232</td>\n",
       "      <td>-5.902471e-01</td>\n",
       "      <td>-0.749246</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.492546</td>\n",
       "      <td>-0.747011</td>\n",
       "      <td>0.961921</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>0.300668</td>\n",
       "      <td>0.209379</td>\n",
       "      <td>-0.299047</td>\n",
       "      <td>0.864595</td>\n",
       "      <td>0.882867</td>\n",
       "      <td>0.028374</td>\n",
       "      <td>0.274604</td>\n",
       "      <td>0.516038</td>\n",
       "      <td>4.890468e-01</td>\n",
       "      <td>0.301919</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.773388</td>\n",
       "      <td>-1.191942</td>\n",
       "      <td>0.090460</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>0.793656</td>\n",
       "      <td>-0.869744</td>\n",
       "      <td>-1.113358</td>\n",
       "      <td>-0.081740</td>\n",
       "      <td>-0.719069</td>\n",
       "      <td>0.260976</td>\n",
       "      <td>-0.059328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000502e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128455</td>\n",
       "      <td>0.661934</td>\n",
       "      <td>-0.345271</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>-0.356650</td>\n",
       "      <td>1.528490</td>\n",
       "      <td>1.727806</td>\n",
       "      <td>0.628011</td>\n",
       "      <td>0.425171</td>\n",
       "      <td>1.191382</td>\n",
       "      <td>4.615720</td>\n",
       "      <td>0.657152</td>\n",
       "      <td>4.658134e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874553</td>\n",
       "      <td>0.291159</td>\n",
       "      <td>-0.563136</td>\n",
       "      <td>-4.614005e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>0.629327</td>\n",
       "      <td>-0.074468</td>\n",
       "      <td>0.332582</td>\n",
       "      <td>1.101179</td>\n",
       "      <td>-0.719069</td>\n",
       "      <td>-1.134635</td>\n",
       "      <td>0.648608</td>\n",
       "      <td>0.758293</td>\n",
       "      <td>-1.318225e+00</td>\n",
       "      <td>0.570937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048214</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>0.961921</td>\n",
       "      <td>7.495288e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>0.793656</td>\n",
       "      <td>0.333993</td>\n",
       "      <td>0.214572</td>\n",
       "      <td>0.628011</td>\n",
       "      <td>-0.547433</td>\n",
       "      <td>-0.669431</td>\n",
       "      <td>0.016363</td>\n",
       "      <td>-0.654663</td>\n",
       "      <td>-5.902471e-01</td>\n",
       "      <td>0.690501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673951</td>\n",
       "      <td>-0.302081</td>\n",
       "      <td>0.961921</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3741 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SAPS-I  Creatinine_last_log  BUN_last_log      SOFA       Age  \\\n",
       "0     0.300668             0.333993      0.085820  0.391428  0.654019   \n",
       "1     1.122315            -1.948867     -2.668222  1.101179 -1.176765   \n",
       "2    -0.027991            -0.629755     -0.299047  1.101179 -0.032525   \n",
       "3     0.793656            -0.869744      1.523650  0.391428  0.768443   \n",
       "4    -0.027991             0.333993      0.151660 -0.081740  0.539595   \n",
       "...        ...                  ...           ...       ...       ...   \n",
       "3736  0.300668             0.209379     -0.299047  0.864595  0.882867   \n",
       "3737  0.793656            -0.869744     -1.113358 -0.081740 -0.719069   \n",
       "3738 -0.356650             1.528490      1.727806  0.628011  0.425171   \n",
       "3739  0.629327            -0.074468      0.332582  1.101179 -0.719069   \n",
       "3740  0.793656             0.333993      0.214572  0.628011 -0.547433   \n",
       "\n",
       "       Na_last    Weight  NIMAP_first    NIMAP_last  Weight_last  ...  \\\n",
       "0    -0.902033 -0.237425    -1.825970 -6.141845e-01    -0.156409  ...   \n",
       "1    -0.204228 -1.096743     1.260974  1.826724e+00    -1.396883  ...   \n",
       "2    -0.669431  1.454497     1.382102 -1.083075e+00     0.000000  ...   \n",
       "3    -0.436830 -1.466295    -0.735819 -1.927924e+00    -1.810374  ...   \n",
       "4     0.028374 -0.678215     0.193232 -5.902471e-01    -0.749246  ...   \n",
       "...        ...       ...          ...           ...          ...  ...   \n",
       "3736  0.028374  0.274604     0.516038  4.890468e-01     0.301919  ...   \n",
       "3737  0.260976 -0.059328     0.000000  1.000502e-15     0.000000  ...   \n",
       "3738  1.191382  4.615720     0.657152  4.658134e-01     0.000000  ...   \n",
       "3739 -1.134635  0.648608     0.758293 -1.318225e+00     0.570937  ...   \n",
       "3740 -0.669431  0.016363    -0.654663 -5.902471e-01     0.690501  ...   \n",
       "\n",
       "      SysABP_diff  DiasABP_diff  FiO2_diff  Lactate_diff  In-hospital_death  \\\n",
       "0        0.032026      1.106864   1.397652  7.908244e-17                  0   \n",
       "1        0.834433      0.736089   1.397652 -1.764760e-01                  0   \n",
       "2        2.318884      0.958554  -0.781002  7.908244e-17                  0   \n",
       "3       -0.970982      1.032709   1.397652 -7.463250e-01                  1   \n",
       "4       -1.492546     -0.747011   0.961921  7.908244e-17                  0   \n",
       "...           ...           ...        ...           ...                ...   \n",
       "3736    -1.773388     -1.191942   0.090460  7.908244e-17                  0   \n",
       "3737    -0.128455      0.661934  -0.345271  7.908244e-17                  1   \n",
       "3738     0.874553      0.291159  -0.563136 -4.614005e-01                  0   \n",
       "3739    -0.048214      0.365314   0.961921  7.495288e-01                  1   \n",
       "3740     0.673951     -0.302081   0.961921  7.908244e-17                  0   \n",
       "\n",
       "      CCU  CSRU  SICU  Gender  MechVentLast8Hour  \n",
       "0       0     1     0     1.0                0.0  \n",
       "1       0     0     0     0.0                1.0  \n",
       "2       1     0     0     1.0                1.0  \n",
       "3       0     0     0     0.0                1.0  \n",
       "4       0     1     0     1.0                0.0  \n",
       "...   ...   ...   ...     ...                ...  \n",
       "3736    0     1     0     1.0                0.0  \n",
       "3737    0     0     1     1.0                1.0  \n",
       "3738    1     0     0     0.0                0.0  \n",
       "3739    0     0     0     1.0                1.0  \n",
       "3740    0     1     0     1.0                0.0  \n",
       "\n",
       "[3741 rows x 40 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(\"df_3.csv\", sep=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3150\n",
      "1     591\n",
      "Name: In-hospital_death, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['In-hospital_death'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0 e t1:  3150 591\n"
     ]
    }
   ],
   "source": [
    "#Downsampling\n",
    "# separare in righe per target\n",
    "t0=df[df['In-hospital_death']==0]\n",
    "t1=df[df['In-hospital_death']==1]\n",
    "print(\"t0 e t1: \", len(t0), len(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t0 down:  591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "t0_down = resample(t0, replace=True, n_samples=591, random_state=123)\n",
    "print(\"t0 down: \", len(t0_down))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAPS-I</th>\n",
       "      <th>Creatinine_last_log</th>\n",
       "      <th>BUN_last_log</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Age</th>\n",
       "      <th>Na_last</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NIMAP_first</th>\n",
       "      <th>NIMAP_last</th>\n",
       "      <th>Weight_last</th>\n",
       "      <th>...</th>\n",
       "      <th>SysABP_diff</th>\n",
       "      <th>DiasABP_diff</th>\n",
       "      <th>FiO2_diff</th>\n",
       "      <th>Lactate_diff</th>\n",
       "      <th>In-hospital_death</th>\n",
       "      <th>CCU</th>\n",
       "      <th>CSRU</th>\n",
       "      <th>SICU</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MechVentLast8Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>-0.685309</td>\n",
       "      <td>-0.629755</td>\n",
       "      <td>-1.280057</td>\n",
       "      <td>-0.081740</td>\n",
       "      <td>-0.490221</td>\n",
       "      <td>-0.204228</td>\n",
       "      <td>0.252342</td>\n",
       "      <td>1.606189</td>\n",
       "      <td>-2.149936e-01</td>\n",
       "      <td>0.112610</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.908499e-18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.345271</td>\n",
       "      <td>-3.189382e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0.136339</td>\n",
       "      <td>-0.421867</td>\n",
       "      <td>-1.469043</td>\n",
       "      <td>-0.318323</td>\n",
       "      <td>-2.664278</td>\n",
       "      <td>-0.204228</td>\n",
       "      <td>-0.348736</td>\n",
       "      <td>0.233204</td>\n",
       "      <td>3.010680e-01</td>\n",
       "      <td>-0.744264</td>\n",
       "      <td>...</td>\n",
       "      <td>9.949138e-01</td>\n",
       "      <td>-0.005461</td>\n",
       "      <td>1.397652</td>\n",
       "      <td>-1.052448e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>0.957986</td>\n",
       "      <td>0.073916</td>\n",
       "      <td>0.151660</td>\n",
       "      <td>1.101179</td>\n",
       "      <td>0.196323</td>\n",
       "      <td>0.493577</td>\n",
       "      <td>1.663761</td>\n",
       "      <td>-1.785392</td>\n",
       "      <td>-9.894380e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.532666e+00</td>\n",
       "      <td>-0.153771</td>\n",
       "      <td>1.397652</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>-0.520979</td>\n",
       "      <td>-0.238498</td>\n",
       "      <td>-0.829350</td>\n",
       "      <td>0.391428</td>\n",
       "      <td>-0.719069</td>\n",
       "      <td>0.493577</td>\n",
       "      <td>1.539093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000502e-15</td>\n",
       "      <td>1.328174</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.895378e-01</td>\n",
       "      <td>-0.450391</td>\n",
       "      <td>0.526190</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>1.450974</td>\n",
       "      <td>-1.500990</td>\n",
       "      <td>-1.687212</td>\n",
       "      <td>1.574346</td>\n",
       "      <td>-2.378218</td>\n",
       "      <td>1.656586</td>\n",
       "      <td>-0.575809</td>\n",
       "      <td>0.576602</td>\n",
       "      <td>-9.190340e-01</td>\n",
       "      <td>-0.814009</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.011102e+00</td>\n",
       "      <td>-0.524546</td>\n",
       "      <td>-1.652463</td>\n",
       "      <td>-1.102481e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>1.450974</td>\n",
       "      <td>0.209379</td>\n",
       "      <td>1.662972</td>\n",
       "      <td>1.574346</td>\n",
       "      <td>0.196323</td>\n",
       "      <td>0.493577</td>\n",
       "      <td>0.697585</td>\n",
       "      <td>-1.623686</td>\n",
       "      <td>-7.078219e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.833465e-02</td>\n",
       "      <td>-0.450391</td>\n",
       "      <td>1.397652</td>\n",
       "      <td>4.738472e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>-0.192320</td>\n",
       "      <td>0.073916</td>\n",
       "      <td>1.618038</td>\n",
       "      <td>1.574346</td>\n",
       "      <td>0.940079</td>\n",
       "      <td>0.958781</td>\n",
       "      <td>-0.949813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000502e-15</td>\n",
       "      <td>-0.978410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.195515e+00</td>\n",
       "      <td>0.291159</td>\n",
       "      <td>-0.781002</td>\n",
       "      <td>5.358354e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>0.300668</td>\n",
       "      <td>0.924799</td>\n",
       "      <td>1.132670</td>\n",
       "      <td>1.101179</td>\n",
       "      <td>1.454988</td>\n",
       "      <td>0.260976</td>\n",
       "      <td>-1.426223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000502e-15</td>\n",
       "      <td>-1.765537</td>\n",
       "      <td>...</td>\n",
       "      <td>3.931091e-01</td>\n",
       "      <td>-0.227926</td>\n",
       "      <td>0.961921</td>\n",
       "      <td>2.509108e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>0.793656</td>\n",
       "      <td>-0.869744</td>\n",
       "      <td>-1.113358</td>\n",
       "      <td>-0.081740</td>\n",
       "      <td>-0.719069</td>\n",
       "      <td>0.260976</td>\n",
       "      <td>-0.059328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000502e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.284550e-01</td>\n",
       "      <td>0.661934</td>\n",
       "      <td>-0.345271</td>\n",
       "      <td>7.908244e-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>0.629327</td>\n",
       "      <td>-0.074468</td>\n",
       "      <td>0.332582</td>\n",
       "      <td>1.101179</td>\n",
       "      <td>-0.719069</td>\n",
       "      <td>-1.134635</td>\n",
       "      <td>0.648608</td>\n",
       "      <td>0.758293</td>\n",
       "      <td>-1.318225e+00</td>\n",
       "      <td>0.570937</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.821433e-02</td>\n",
       "      <td>0.365314</td>\n",
       "      <td>0.961921</td>\n",
       "      <td>7.495288e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1182 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SAPS-I  Creatinine_last_log  BUN_last_log      SOFA       Age  \\\n",
       "1604 -0.685309            -0.629755     -1.280057 -0.081740 -0.490221   \n",
       "1342  0.136339            -0.421867     -1.469043 -0.318323 -2.664278   \n",
       "2099  0.957986             0.073916      0.151660  1.101179  0.196323   \n",
       "3658 -0.520979            -0.238498     -0.829350  0.391428 -0.719069   \n",
       "2553  1.450974            -1.500990     -1.687212  1.574346 -2.378218   \n",
       "...        ...                  ...           ...       ...       ...   \n",
       "3728  1.450974             0.209379      1.662972  1.574346  0.196323   \n",
       "3729 -0.192320             0.073916      1.618038  1.574346  0.940079   \n",
       "3731  0.300668             0.924799      1.132670  1.101179  1.454988   \n",
       "3737  0.793656            -0.869744     -1.113358 -0.081740 -0.719069   \n",
       "3739  0.629327            -0.074468      0.332582  1.101179 -0.719069   \n",
       "\n",
       "       Na_last    Weight  NIMAP_first    NIMAP_last  Weight_last  ...  \\\n",
       "1604 -0.204228  0.252342     1.606189 -2.149936e-01     0.112610  ...   \n",
       "1342 -0.204228 -0.348736     0.233204  3.010680e-01    -0.744264  ...   \n",
       "2099  0.493577  1.663761    -1.785392 -9.894380e-01     0.000000  ...   \n",
       "3658  0.493577  1.539093     0.000000  1.000502e-15     1.328174  ...   \n",
       "2553  1.656586 -0.575809     0.576602 -9.190340e-01    -0.814009  ...   \n",
       "...        ...       ...          ...           ...          ...  ...   \n",
       "3728  0.493577  0.697585    -1.623686 -7.078219e-01     0.000000  ...   \n",
       "3729  0.958781 -0.949813     0.000000  1.000502e-15    -0.978410  ...   \n",
       "3731  0.260976 -1.426223     0.000000  1.000502e-15    -1.765537  ...   \n",
       "3737  0.260976 -0.059328     0.000000  1.000502e-15     0.000000  ...   \n",
       "3739 -1.134635  0.648608     0.758293 -1.318225e+00     0.570937  ...   \n",
       "\n",
       "       SysABP_diff  DiasABP_diff  FiO2_diff  Lactate_diff  In-hospital_death  \\\n",
       "1604 -8.908499e-18      0.000000  -0.345271 -3.189382e-01                  0   \n",
       "1342  9.949138e-01     -0.005461   1.397652 -1.052448e-01                  0   \n",
       "2099 -1.532666e+00     -0.153771   1.397652  7.908244e-17                  0   \n",
       "3658 -4.895378e-01     -0.450391   0.526190  7.908244e-17                  0   \n",
       "2553 -1.011102e+00     -0.524546  -1.652463 -1.102481e+00                  0   \n",
       "...            ...           ...        ...           ...                ...   \n",
       "3728 -8.833465e-02     -0.450391   1.397652  4.738472e+00                  1   \n",
       "3729  1.195515e+00      0.291159  -0.781002  5.358354e-01                  1   \n",
       "3731  3.931091e-01     -0.227926   0.961921  2.509108e-01                  1   \n",
       "3737 -1.284550e-01      0.661934  -0.345271  7.908244e-17                  1   \n",
       "3739 -4.821433e-02      0.365314   0.961921  7.495288e-01                  1   \n",
       "\n",
       "      CCU  CSRU  SICU  Gender  MechVentLast8Hour  \n",
       "1604    0     0     1     1.0                1.0  \n",
       "1342    0     0     1     1.0                1.0  \n",
       "2099    0     1     0     1.0                0.0  \n",
       "3658    0     1     0     0.0                0.0  \n",
       "2553    0     0     0     1.0                1.0  \n",
       "...   ...   ...   ...     ...                ...  \n",
       "3728    1     0     0     1.0                1.0  \n",
       "3729    0     0     0     0.0                1.0  \n",
       "3731    0     1     0     0.0                1.0  \n",
       "3737    0     0     1     1.0                1.0  \n",
       "3739    0     0     0     1.0                1.0  \n",
       "\n",
       "[1182 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([t0_down, t1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 39) (355, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "#TROVARE MODO DI PESARE IL TARGET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "y=df['In-hospital_death']\n",
    "x= df.drop(['In-hospital_death'], axis=1)\n",
    "X_train, X_test, y_train, y_test=train_test_split(x, y, test_size=0.3, stratify=y, random_state=123)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hyperp_search(classifier, parameters):\n",
    "    gs = GridSearchCV(classifier, parameters, cv=5, scoring = 'f1', verbose=0, n_jobs=-1)\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    print(\"f1_train: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "\n",
    "    best_model = gs.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(\"f1_test: \", f1_score(y_test, y_pred), \"\\n\\n\")\n",
    "    print(confusion_matrix(y_test, y_pred), \"\\n\\n\")\n",
    "    print(classification_report(y_test, y_pred), \"\\n\\n\")\n",
    "\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(recall, precision, color='purple')\n",
    "\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xlabel('Recall')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def roc(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds1 = metrics.roc_curve(y_test, y_probs[:, 1])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(fpr, tpr, label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('FP Rate')\n",
    "    plt.ylabel('TP Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test, y_probs[:, 1])\n",
    "    print('AUC: %.2f' % auc)\n",
    "    return (fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':np.arange(10,100, 1000)}\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "fpr1, tpr1 = roc(model_knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "parameters = {'criterion': ['entropy','gini'], 'max_depth': [4,5,10], 'min_samples_split': [20],'min_samples_leaf': [10], 'class_weight':['balanced']}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=10, min_samples_split=20)\n",
    "\n",
    "fpr2,tpr2=roc(model_tree,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB #or alternative NB implementations\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1_score: \", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"f1_test: \", f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(X_test) #predict_proba gives the probabilities for the target (0 and 1 in your case)\n",
    "\n",
    "fpr3,tpr3=roc(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "parameters = {\"C\":[1e-4,1e-3,1e-2,1e-1,1,10], \"max_iter\":[1000], 'class_weight':['balanced']}\n",
    "\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.0001, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "fpr4,tpr4=roc(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {\"kernel\":['linear', 'rbf'], \"C\":[0.1, 1], \"class_weight\":['balanced']}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = SVC(C=0.1, kernel='rbf',probability=True, class_weight='balanced')\n",
    "\n",
    "fpr5,tpr5=roc(model,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron classifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "parameters = {\"hidden_layer_sizes\":[(10, 5),(20,5)],  \"max_iter\": [1000], \"alpha\": [0.001,0.1]}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_MLP=MLPClassifier(hidden_layer_sizes=(20,5), alpha=0.1, max_iter=1000)\n",
    "\n",
    "fpr6,tpr6=roc(model_MLP,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(n_estimators=50, random_state=123)\n",
    "parameters={'criterion': ['entropy','gini'], 'max_depth': [4,5,10], 'min_samples_leaf': [5, 10],'min_samples_split': [5, 10]}\n",
    "\n",
    "def hyperp_search(classifier, parameters):\n",
    "    gs=GridSearchCV(classifier, parameters, cv=3, scoring = 'f1', verbose=0, n_jobs=-1)\n",
    "    gs=gs.fit(X_train, y_train)\n",
    "    print(\"f1_train: %f using %s\" %(gs.best_score_, gs.best_params_))\n",
    "\n",
    "    best_model=gs.best_estimator_\n",
    "    y_pred=best_model.predict(X_test)\n",
    "\n",
    "    print(\"f1_test: \", f1_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_RF=RandomForestClassifier(criterion='gini', max_depth=10, min_samples_leaf=5, min_samples_split=5)\n",
    "\n",
    "fpr7,tpr7=roc(model_RF,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr1, tpr1, label= \"KNN\")\n",
    "plt.plot(fpr2, tpr2, label= \"Tree\")\n",
    "plt.plot(fpr3, tpr3, label= \"NB\")\n",
    "plt.plot(fpr4, tpr4, label= \"Logistic\")\n",
    "plt.plot(fpr5, tpr5, label= \"SVM\")\n",
    "plt.plot(fpr6, tpr6, label= \"NeuralNet\")\n",
    "plt.plot(fpr7, tpr7, label= \"Random Forest\")\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827, 39) (355, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "y=df['In-hospital_death']\n",
    "x= df.drop(['In-hospital_death'], axis=1)\n",
    "X, X_test, y, y_test=train_test_split(x, y, test_size=0.3, stratify=y, random_state=123)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578, 39) (249, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_tuner, X_val_tuner, y_train_tuner, y_val_tuner = train_test_split(X, y, test_size=0.3, stratify=y, random_state=123)\n",
    "\n",
    "print(X_train_tuner.shape, X_val_tuner.shape)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Sequential model \n",
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(1, activation=\"softmax\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.5020080208778381\n",
      "\n",
      "Best val_accuracy So Far: 0.5020080208778381\n",
      "Total elapsed time: 00h 00m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_tuner, y_train_tuner, epochs=2, validation_data=(X_val_tuner, y_val_tuner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 39)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 320)               12800     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                10272     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,161\n",
      "Trainable params: 24,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 39))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_dir/helloworld\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fe384dec700>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 320\n",
      "activation: tanh\n",
      "dropout: False\n",
      "lr: 0.007121095343791048\n",
      "units_1: 32\n",
      "units_2: 32\n",
      "Score: 0.5020080208778381\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 416\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.0017311246306854196\n",
      "units_1: 64\n",
      "units_2: 96\n",
      "Score: 0.5020080208778381\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 352\n",
      "activation: tanh\n",
      "dropout: False\n",
      "lr: 0.003378131836989523\n",
      "units_1: 224\n",
      "units_2: 384\n",
      "Score: 0.5020080208778381\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.5006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3848c6550>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = build_model(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((X_train_tuner, X_val_tuner))\n",
    "y_all = np.concatenate((y_train_tuner, y_val_tuner))\n",
    "model.fit(x=x_all, y=y_all, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Performances:\n",
    "# minimum sensitivity and precision\n",
    "# area under precision-recall curve\n",
    "# area under reciving operating curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ROC curve function \n",
    "# https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "\n",
    "\n",
    "def ROC_curve(model, testX, testy)\n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(testy))]\n",
    "    lr_probs = model.predict_proba(testX)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(testy, ns_probs)\n",
    "    lr_auc = roc_auc_score(testy, lr_probs)\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "    # plot the roc curve for the model\n",
    "    pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (advancedSP)",
   "language": "python",
   "name": "pycharm-851f1b39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
