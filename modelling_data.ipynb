{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modelling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "        SAPS-I  Creatinine_last_log      SOFA       Age  BUN_last   Na_last  \\\n0    -1.342626            -0.356675 -1.264658 -0.604645 -0.854315 -0.669431   \n1     0.300668             0.262364  0.391428  0.654019 -0.218095 -0.902033   \n2     1.122315            -1.203973  1.101179 -1.176765 -1.099015 -0.204228   \n3    -1.178297            -0.356675 -1.264658  0.196323 -0.756435 -0.436830   \n4     0.464998             0.000000 -1.028074  1.340564 -0.022335  0.028374   \n...        ...                  ...       ...       ...       ...       ...   \n5989  0.793656            -0.510826 -0.081740 -0.719069 -0.805375  0.260976   \n5990 -0.192320            -0.356675 -1.028074  1.454988 -0.120215 -2.297644   \n5991 -0.356650             1.029619  0.628011  0.425171  2.033144  1.191382   \n5992  0.629327             0.000000  1.101179 -0.719069 -0.022335 -1.134635   \n5993  0.793656             0.262364  0.628011 -0.547433 -0.120215 -0.669431   \n\n            Weight  NIMAP_first    NIMAP_last  HCT_diff  ...  NISysABP_diff  \\\n0    -6.327279e-16     0.778279  1.602599e-01  0.475613  ...       0.720286   \n1    -2.374250e-01    -1.825970 -6.141845e-01 -1.211401  ...      -1.574997   \n2    -1.096743e+00     1.260974  1.826724e+00 -0.419962  ...      -0.427355   \n3     1.454837e-01     0.435488  1.521874e+00  0.808850  ...      -0.087313   \n4    -6.327279e-16    -0.251308 -2.853976e-01 -1.961185  ...       0.295234   \n...            ...          ...           ...       ...  ...            ...   \n5989 -5.932794e-02     0.000000  1.000502e-15  0.496440  ...       0.000000   \n5990 -4.155221e-01     1.162255  8.410670e-01 -1.482156  ...       0.720286   \n5991  4.615720e+00     0.657152  4.658134e-01  0.371476  ...      -0.257334   \n5992  6.486079e-01     0.758293 -1.318225e+00 -1.627947  ...       1.655402   \n5993  1.636332e-02    -0.654663 -5.902471e-01 -2.086149  ...      -0.087313   \n\n      NIDiasABP_diff       pH_diff     PaO2_diff    PaCO2_diff  \\\n0       4.397396e-01 -8.646334e-17  1.318287e-16  2.766267e-17   \n1      -8.330336e-01  1.361086e+00  1.089787e+00 -1.666857e+00   \n2      -1.663429e-01  8.626583e-01 -1.804519e+00 -1.718778e-01   \n3      -1.257291e+00 -8.646334e-17  1.318287e-16  2.766267e-17   \n4      -2.269512e-01 -8.646334e-17  1.318287e-16  2.766267e-17   \n...              ...           ...           ...           ...   \n5989   -2.691547e-17 -9.589378e-03  1.507234e+00  4.510303e-01   \n5990    1.366983e-01 -8.646334e-17  1.318287e-16  2.766267e-17   \n5991    5.609560e-01 -1.131051e+00 -1.201539e+00  2.818081e+00   \n5992    1.651904e+00 -3.834098e-01 -7.284314e-01 -1.293112e+00   \n5993   -1.663429e-01 -1.006444e+00  1.971066e+00  1.447683e+00   \n\n      In-hospital_death  CCU  CSRU  SICU  Gender  \n0                     0    0     0     1     0.0  \n1                     0    0     1     0     1.0  \n2                     0    0     0     0     0.0  \n3                     0    0     0     0     1.0  \n4                     0    0     0     0     0.0  \n...                 ...  ...   ...   ...     ...  \n5989                  1    0     0     1     1.0  \n5990                  0    1     0     0     0.0  \n5991                  0    1     0     0     0.0  \n5992                  1    0     0     0     1.0  \n5993                  0    0     1     0     1.0  \n\n[5994 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAPS-I</th>\n      <th>Creatinine_last_log</th>\n      <th>SOFA</th>\n      <th>Age</th>\n      <th>BUN_last</th>\n      <th>Na_last</th>\n      <th>Weight</th>\n      <th>NIMAP_first</th>\n      <th>NIMAP_last</th>\n      <th>HCT_diff</th>\n      <th>...</th>\n      <th>NISysABP_diff</th>\n      <th>NIDiasABP_diff</th>\n      <th>pH_diff</th>\n      <th>PaO2_diff</th>\n      <th>PaCO2_diff</th>\n      <th>In-hospital_death</th>\n      <th>CCU</th>\n      <th>CSRU</th>\n      <th>SICU</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.342626</td>\n      <td>-0.356675</td>\n      <td>-1.264658</td>\n      <td>-0.604645</td>\n      <td>-0.854315</td>\n      <td>-0.669431</td>\n      <td>-6.327279e-16</td>\n      <td>0.778279</td>\n      <td>1.602599e-01</td>\n      <td>0.475613</td>\n      <td>...</td>\n      <td>0.720286</td>\n      <td>4.397396e-01</td>\n      <td>-8.646334e-17</td>\n      <td>1.318287e-16</td>\n      <td>2.766267e-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.300668</td>\n      <td>0.262364</td>\n      <td>0.391428</td>\n      <td>0.654019</td>\n      <td>-0.218095</td>\n      <td>-0.902033</td>\n      <td>-2.374250e-01</td>\n      <td>-1.825970</td>\n      <td>-6.141845e-01</td>\n      <td>-1.211401</td>\n      <td>...</td>\n      <td>-1.574997</td>\n      <td>-8.330336e-01</td>\n      <td>1.361086e+00</td>\n      <td>1.089787e+00</td>\n      <td>-1.666857e+00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.122315</td>\n      <td>-1.203973</td>\n      <td>1.101179</td>\n      <td>-1.176765</td>\n      <td>-1.099015</td>\n      <td>-0.204228</td>\n      <td>-1.096743e+00</td>\n      <td>1.260974</td>\n      <td>1.826724e+00</td>\n      <td>-0.419962</td>\n      <td>...</td>\n      <td>-0.427355</td>\n      <td>-1.663429e-01</td>\n      <td>8.626583e-01</td>\n      <td>-1.804519e+00</td>\n      <td>-1.718778e-01</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.178297</td>\n      <td>-0.356675</td>\n      <td>-1.264658</td>\n      <td>0.196323</td>\n      <td>-0.756435</td>\n      <td>-0.436830</td>\n      <td>1.454837e-01</td>\n      <td>0.435488</td>\n      <td>1.521874e+00</td>\n      <td>0.808850</td>\n      <td>...</td>\n      <td>-0.087313</td>\n      <td>-1.257291e+00</td>\n      <td>-8.646334e-17</td>\n      <td>1.318287e-16</td>\n      <td>2.766267e-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.464998</td>\n      <td>0.000000</td>\n      <td>-1.028074</td>\n      <td>1.340564</td>\n      <td>-0.022335</td>\n      <td>0.028374</td>\n      <td>-6.327279e-16</td>\n      <td>-0.251308</td>\n      <td>-2.853976e-01</td>\n      <td>-1.961185</td>\n      <td>...</td>\n      <td>0.295234</td>\n      <td>-2.269512e-01</td>\n      <td>-8.646334e-17</td>\n      <td>1.318287e-16</td>\n      <td>2.766267e-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5989</th>\n      <td>0.793656</td>\n      <td>-0.510826</td>\n      <td>-0.081740</td>\n      <td>-0.719069</td>\n      <td>-0.805375</td>\n      <td>0.260976</td>\n      <td>-5.932794e-02</td>\n      <td>0.000000</td>\n      <td>1.000502e-15</td>\n      <td>0.496440</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>-2.691547e-17</td>\n      <td>-9.589378e-03</td>\n      <td>1.507234e+00</td>\n      <td>4.510303e-01</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5990</th>\n      <td>-0.192320</td>\n      <td>-0.356675</td>\n      <td>-1.028074</td>\n      <td>1.454988</td>\n      <td>-0.120215</td>\n      <td>-2.297644</td>\n      <td>-4.155221e-01</td>\n      <td>1.162255</td>\n      <td>8.410670e-01</td>\n      <td>-1.482156</td>\n      <td>...</td>\n      <td>0.720286</td>\n      <td>1.366983e-01</td>\n      <td>-8.646334e-17</td>\n      <td>1.318287e-16</td>\n      <td>2.766267e-17</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5991</th>\n      <td>-0.356650</td>\n      <td>1.029619</td>\n      <td>0.628011</td>\n      <td>0.425171</td>\n      <td>2.033144</td>\n      <td>1.191382</td>\n      <td>4.615720e+00</td>\n      <td>0.657152</td>\n      <td>4.658134e-01</td>\n      <td>0.371476</td>\n      <td>...</td>\n      <td>-0.257334</td>\n      <td>5.609560e-01</td>\n      <td>-1.131051e+00</td>\n      <td>-1.201539e+00</td>\n      <td>2.818081e+00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5992</th>\n      <td>0.629327</td>\n      <td>0.000000</td>\n      <td>1.101179</td>\n      <td>-0.719069</td>\n      <td>-0.022335</td>\n      <td>-1.134635</td>\n      <td>6.486079e-01</td>\n      <td>0.758293</td>\n      <td>-1.318225e+00</td>\n      <td>-1.627947</td>\n      <td>...</td>\n      <td>1.655402</td>\n      <td>1.651904e+00</td>\n      <td>-3.834098e-01</td>\n      <td>-7.284314e-01</td>\n      <td>-1.293112e+00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5993</th>\n      <td>0.793656</td>\n      <td>0.262364</td>\n      <td>0.628011</td>\n      <td>-0.547433</td>\n      <td>-0.120215</td>\n      <td>-0.669431</td>\n      <td>1.636332e-02</td>\n      <td>-0.654663</td>\n      <td>-5.902471e-01</td>\n      <td>-2.086149</td>\n      <td>...</td>\n      <td>-0.087313</td>\n      <td>-1.663429e-01</td>\n      <td>-1.006444e+00</td>\n      <td>1.971066e+00</td>\n      <td>1.447683e+00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5994 rows Ã— 29 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(\"df_2.csv\", sep=\",\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df['In-hospital_death'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Downsampling\n",
    "# separare in righe per target\n",
    "t0=df[df['In-hospital_death']==0]\n",
    "t1=df[df['In-hospital_death']==1]\n",
    "print(\"t0 e t1: \", len(t0), len(t1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "t0_down = resample(t0, replace=True, n_samples=len(t1), random_state=123)\n",
    "print(\"t0 down: \", len(t0_down))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.concat([t0_down, t1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train test split\n",
    "\n",
    "#TROVARE MODO DI PESARE IL TARGET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "y=df['In-hospital_death']\n",
    "x= df.drop(['In-hospital_death'], axis=1)\n",
    "X_train, X_test, y_train, y_test=train_test_split(x, y, test_size=0.30, stratify=y, random_state=123)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "type(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hyperp_search(classifier, parameters):\n",
    "    gs = GridSearchCV(classifier, parameters, cv=5, scoring = 'f1', verbose=0, n_jobs=-1)\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    print(\"f1_train: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "\n",
    "    best_model = gs.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(\"f1_test: \", f1_score(y_test, y_pred), \"\\n\\n\")\n",
    "    print(confusion_matrix(y_test, y_pred), \"\\n\\n\")\n",
    "    print(classification_report(y_test, y_pred), \"\\n\\n\")\n",
    "\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(recall, precision, color='purple')\n",
    "\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xlabel('Recall')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def roc(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds1 = metrics.roc_curve(y_test, y_probs[:, 1])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(fpr, tpr, label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('FP Rate')\n",
    "    plt.ylabel('TP Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test, y_probs[:, 1])\n",
    "    print('AUC: %.2f' % auc)\n",
    "    return (fpr, tpr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':np.arange(10,100, 1000)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "fpr1, tpr1 = roc(model_knn, X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "parameters = {'criterion': ['entropy','gini'], 'max_depth': [4,5,10], 'min_samples_split': [20],'min_samples_leaf': [10], 'class_weight':['balanced']}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(criterion='gini', max_depth=4, min_samples_leaf=10, min_samples_split=20)\n",
    "\n",
    "fpr2,tpr2=roc(model_tree,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB #or alternative NB implementations\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1_score: \", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"f1_test: \", f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_probs = model.predict_proba(X_test) #predict_proba gives the probabilities for the target (0 and 1 in your case)\n",
    "\n",
    "fpr3,tpr3=roc(model,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "parameters = {\"C\":[1e-4,1e-3,1e-2,1e-1,1,10], \"max_iter\":[1000]}\n",
    "\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.1, max_iter=1000)\n",
    "\n",
    "fpr4,tpr4=roc(model,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {\"kernel\":['linear', 'rbf'], \"C\":[0.1, 1]}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SVC(C=0.1, kernel='rbf',probability=True, class_weight='balanced')\n",
    "\n",
    "fpr5,tpr5=roc(model,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron classifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "parameters = {\"hidden_layer_sizes\":[(10, 5),(20,5)],  \"max_iter\": [1000], \"alpha\": [0.001,0.1]}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_MLP=MLPClassifier(hidden_layer_sizes=(10,5), alpha=0.001, max_iter=1000)\n",
    "\n",
    "fpr6,tpr6=roc(model_MLP,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(n_estimators=10, random_state=123, class_weight='balanced')\n",
    "parameters={'criterion': ['entropy','gini'], 'max_depth': [4,5,10], 'min_samples_leaf': [5, 10],'min_samples_split': [5, 10]}\n",
    "\n",
    "def hyperp_search(classifier, parameters):\n",
    "    gs=GridSearchCV(classifier, parameters, cv=3, scoring = 'f1', verbose=0, n_jobs=-1)\n",
    "    gs=gs.fit(X_train, y_train)\n",
    "    print(\"f1_train: %f using %s\" %(gs.best_score_, gs.best_params_))\n",
    "\n",
    "    best_model=gs.best_estimator_\n",
    "    y_pred=best_model.predict(X_test)\n",
    "\n",
    "    print(\"f1_test: \", f1_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_RF=RandomForestClassifier(criterion='entropy', max_depth=5, min_samples_leaf=10, min_samples_split=5)\n",
    "\n",
    "fpr7,tpr7=roc(model_RF,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr1, tpr1, label= \"KNN\")\n",
    "plt.plot(fpr2, tpr2, label= \"Tree\")\n",
    "plt.plot(fpr3, tpr3, label= \"NB\")\n",
    "plt.plot(fpr4, tpr4, label= \"Logistic\")\n",
    "plt.plot(fpr5, tpr5, label= \"SVM\")\n",
    "plt.plot(fpr6, tpr6, label= \"NeuralNet\")\n",
    "plt.plot(fpr7, tpr7, label= \"Random Forest\")\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# models vari\n",
    "\n",
    "# SVM\n",
    "\n",
    "# k-NN\n",
    "\n",
    "# Tree / Random forest\n",
    "\n",
    "# Ada boost (?) random forest con diversi modelli\n",
    "\n",
    "# Neural network composta di pochi dense layer insieme\n",
    "\n",
    "\n",
    "# all to use with class_weight parameter \n",
    "\n",
    "#DecisionTreeClassifier\n",
    "#LogisticRegression\n",
    "#RidgeClassifier\n",
    "#The Keras Python Deep Learning "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Performances:\n",
    "# minimum sensitivity and precision\n",
    "# area under precision-recall curve\n",
    "# area under reciving operating curve\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Computing sensitivity and precision \n",
    "def metrics(): \n",
    "    results = []\n",
    "    \n",
    "    return results\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ROC curve function \n",
    "# https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "\n",
    "\n",
    "def ROC_curve(model, testX, testy)\n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(testy))]\n",
    "    lr_probs = model.predict_proba(testX)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(testy, ns_probs)\n",
    "    lr_auc = roc_auc_score(testy, lr_probs)\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "    # plot the roc curve for the model\n",
    "    pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-851f1b39",
   "language": "python",
   "display_name": "PyCharm (advancedSP)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}