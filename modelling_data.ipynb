{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modelling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "        SAPS-I  Creatinine_last_log  BUN_last_log      SOFA       Age  \\\n0     0.300668             0.333993      0.085820  0.391428  0.654019   \n1     1.122315            -1.948867     -2.668222  1.101179 -1.176765   \n2    -0.027991            -0.629755     -0.299047  1.101179 -0.032525   \n3     0.793656            -0.869744      1.523650  0.391428  0.768443   \n4    -0.027991             0.333993      0.151660 -0.081740  0.539595   \n...        ...                  ...           ...       ...       ...   \n3736  0.300668             0.209379     -0.299047  0.864595  0.882867   \n3737  0.793656            -0.869744     -1.113358 -0.081740 -0.719069   \n3738 -0.356650             1.528490      1.727806  0.628011  0.425171   \n3739  0.629327            -0.074468      0.332582  1.101179 -0.719069   \n3740  0.793656             0.333993      0.214572  0.628011 -0.547433   \n\n       Na_last    Weight  NIMAP_first    NIMAP_last  Weight_last  ...  \\\n0    -0.902033 -0.237425    -1.825970 -6.141845e-01    -0.156409  ...   \n1    -0.204228 -1.096743     1.260974  1.826724e+00    -1.396883  ...   \n2    -0.669431  1.454497     1.382102 -1.083075e+00     0.000000  ...   \n3    -0.436830 -1.466295    -0.735819 -1.927924e+00    -1.810374  ...   \n4     0.028374 -0.678215     0.193232 -5.902471e-01    -0.749246  ...   \n...        ...       ...          ...           ...          ...  ...   \n3736  0.028374  0.274604     0.516038  4.890468e-01     0.301919  ...   \n3737  0.260976 -0.059328     0.000000  1.000502e-15     0.000000  ...   \n3738  1.191382  4.615720     0.657152  4.658134e-01     0.000000  ...   \n3739 -1.134635  0.648608     0.758293 -1.318225e+00     0.570937  ...   \n3740 -0.669431  0.016363    -0.654663 -5.902471e-01     0.690501  ...   \n\n      SysABP_diff  DiasABP_diff  FiO2_diff  Lactate_diff  In-hospital_death  \\\n0        0.032026      1.106864   1.397652  7.908244e-17                  0   \n1        0.834433      0.736089   1.397652 -1.764760e-01                  0   \n2        2.318884      0.958554  -0.781002  7.908244e-17                  0   \n3       -0.970982      1.032709   1.397652 -7.463250e-01                  1   \n4       -1.492546     -0.747011   0.961921  7.908244e-17                  0   \n...           ...           ...        ...           ...                ...   \n3736    -1.773388     -1.191942   0.090460  7.908244e-17                  0   \n3737    -0.128455      0.661934  -0.345271  7.908244e-17                  1   \n3738     0.874553      0.291159  -0.563136 -4.614005e-01                  0   \n3739    -0.048214      0.365314   0.961921  7.495288e-01                  1   \n3740     0.673951     -0.302081   0.961921  7.908244e-17                  0   \n\n      CCU  CSRU  SICU  Gender  MechVentLast8Hour  \n0       0     1     0     1.0                0.0  \n1       0     0     0     0.0                1.0  \n2       1     0     0     1.0                1.0  \n3       0     0     0     0.0                1.0  \n4       0     1     0     1.0                0.0  \n...   ...   ...   ...     ...                ...  \n3736    0     1     0     1.0                0.0  \n3737    0     0     1     1.0                1.0  \n3738    1     0     0     0.0                0.0  \n3739    0     0     0     1.0                1.0  \n3740    0     1     0     1.0                0.0  \n\n[3741 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SAPS-I</th>\n      <th>Creatinine_last_log</th>\n      <th>BUN_last_log</th>\n      <th>SOFA</th>\n      <th>Age</th>\n      <th>Na_last</th>\n      <th>Weight</th>\n      <th>NIMAP_first</th>\n      <th>NIMAP_last</th>\n      <th>Weight_last</th>\n      <th>...</th>\n      <th>SysABP_diff</th>\n      <th>DiasABP_diff</th>\n      <th>FiO2_diff</th>\n      <th>Lactate_diff</th>\n      <th>In-hospital_death</th>\n      <th>CCU</th>\n      <th>CSRU</th>\n      <th>SICU</th>\n      <th>Gender</th>\n      <th>MechVentLast8Hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.300668</td>\n      <td>0.333993</td>\n      <td>0.085820</td>\n      <td>0.391428</td>\n      <td>0.654019</td>\n      <td>-0.902033</td>\n      <td>-0.237425</td>\n      <td>-1.825970</td>\n      <td>-6.141845e-01</td>\n      <td>-0.156409</td>\n      <td>...</td>\n      <td>0.032026</td>\n      <td>1.106864</td>\n      <td>1.397652</td>\n      <td>7.908244e-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.122315</td>\n      <td>-1.948867</td>\n      <td>-2.668222</td>\n      <td>1.101179</td>\n      <td>-1.176765</td>\n      <td>-0.204228</td>\n      <td>-1.096743</td>\n      <td>1.260974</td>\n      <td>1.826724e+00</td>\n      <td>-1.396883</td>\n      <td>...</td>\n      <td>0.834433</td>\n      <td>0.736089</td>\n      <td>1.397652</td>\n      <td>-1.764760e-01</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.027991</td>\n      <td>-0.629755</td>\n      <td>-0.299047</td>\n      <td>1.101179</td>\n      <td>-0.032525</td>\n      <td>-0.669431</td>\n      <td>1.454497</td>\n      <td>1.382102</td>\n      <td>-1.083075e+00</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>2.318884</td>\n      <td>0.958554</td>\n      <td>-0.781002</td>\n      <td>7.908244e-17</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.793656</td>\n      <td>-0.869744</td>\n      <td>1.523650</td>\n      <td>0.391428</td>\n      <td>0.768443</td>\n      <td>-0.436830</td>\n      <td>-1.466295</td>\n      <td>-0.735819</td>\n      <td>-1.927924e+00</td>\n      <td>-1.810374</td>\n      <td>...</td>\n      <td>-0.970982</td>\n      <td>1.032709</td>\n      <td>1.397652</td>\n      <td>-7.463250e-01</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.027991</td>\n      <td>0.333993</td>\n      <td>0.151660</td>\n      <td>-0.081740</td>\n      <td>0.539595</td>\n      <td>0.028374</td>\n      <td>-0.678215</td>\n      <td>0.193232</td>\n      <td>-5.902471e-01</td>\n      <td>-0.749246</td>\n      <td>...</td>\n      <td>-1.492546</td>\n      <td>-0.747011</td>\n      <td>0.961921</td>\n      <td>7.908244e-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3736</th>\n      <td>0.300668</td>\n      <td>0.209379</td>\n      <td>-0.299047</td>\n      <td>0.864595</td>\n      <td>0.882867</td>\n      <td>0.028374</td>\n      <td>0.274604</td>\n      <td>0.516038</td>\n      <td>4.890468e-01</td>\n      <td>0.301919</td>\n      <td>...</td>\n      <td>-1.773388</td>\n      <td>-1.191942</td>\n      <td>0.090460</td>\n      <td>7.908244e-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3737</th>\n      <td>0.793656</td>\n      <td>-0.869744</td>\n      <td>-1.113358</td>\n      <td>-0.081740</td>\n      <td>-0.719069</td>\n      <td>0.260976</td>\n      <td>-0.059328</td>\n      <td>0.000000</td>\n      <td>1.000502e-15</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>-0.128455</td>\n      <td>0.661934</td>\n      <td>-0.345271</td>\n      <td>7.908244e-17</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3738</th>\n      <td>-0.356650</td>\n      <td>1.528490</td>\n      <td>1.727806</td>\n      <td>0.628011</td>\n      <td>0.425171</td>\n      <td>1.191382</td>\n      <td>4.615720</td>\n      <td>0.657152</td>\n      <td>4.658134e-01</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.874553</td>\n      <td>0.291159</td>\n      <td>-0.563136</td>\n      <td>-4.614005e-01</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3739</th>\n      <td>0.629327</td>\n      <td>-0.074468</td>\n      <td>0.332582</td>\n      <td>1.101179</td>\n      <td>-0.719069</td>\n      <td>-1.134635</td>\n      <td>0.648608</td>\n      <td>0.758293</td>\n      <td>-1.318225e+00</td>\n      <td>0.570937</td>\n      <td>...</td>\n      <td>-0.048214</td>\n      <td>0.365314</td>\n      <td>0.961921</td>\n      <td>7.495288e-01</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3740</th>\n      <td>0.793656</td>\n      <td>0.333993</td>\n      <td>0.214572</td>\n      <td>0.628011</td>\n      <td>-0.547433</td>\n      <td>-0.669431</td>\n      <td>0.016363</td>\n      <td>-0.654663</td>\n      <td>-5.902471e-01</td>\n      <td>0.690501</td>\n      <td>...</td>\n      <td>0.673951</td>\n      <td>-0.302081</td>\n      <td>0.961921</td>\n      <td>7.908244e-17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3741 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(\"df_3.csv\", sep=\",\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3150\n",
      "1     591\n",
      "Name: In-hospital_death, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['In-hospital_death'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Downsampling\n",
    "# separare in righe per target\n",
    "t0=df[df['In-hospital_death']==0]\n",
    "t1=df[df['In-hospital_death']==1]\n",
    "print(\"t0 e t1: \", len(t0), len(t1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "t0_down = resample(t0, replace=True, n_samples=591, random_state=123)\n",
    "print(\"t0 down: \", len(t0_down))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.concat([t0_down, t1])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train test split\n",
    "\n",
    "#TROVARE MODO DI PESARE IL TARGET\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "y=df['In-hospital_death']\n",
    "x= df.drop(['In-hospital_death'], axis=1)\n",
    "X_train, X_test, y_train, y_test=train_test_split(x, y, test_size=0.3, stratify=y, random_state=123)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "type(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hyperp_search(classifier, parameters):\n",
    "    gs = GridSearchCV(classifier, parameters, cv=5, scoring = 'f1', verbose=0, n_jobs=-1)\n",
    "    gs = gs.fit(X_train, y_train)\n",
    "    print(\"f1_train: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "\n",
    "    best_model = gs.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(\"f1_test: \", f1_score(y_test, y_pred), \"\\n\\n\")\n",
    "    print(confusion_matrix(y_test, y_pred), \"\\n\\n\")\n",
    "    print(classification_report(y_test, y_pred), \"\\n\\n\")\n",
    "\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(recall, precision, color='purple')\n",
    "\n",
    "    ax.set_title('Precision-Recall Curve')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_xlabel('Recall')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def roc(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_probs = model.predict_proba(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds1 = metrics.roc_curve(y_test, y_probs[:, 1])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(fpr, tpr, label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('FP Rate')\n",
    "    plt.ylabel('TP Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    auc = metrics.roc_auc_score(y_test, y_probs[:, 1])\n",
    "    print('AUC: %.2f' % auc)\n",
    "    return (fpr, tpr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':np.arange(10,100, 1000)}\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "fpr1, tpr1 = roc(model_knn, X_train, y_train, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "parameters = {'criterion': ['entropy','gini'], 'max_depth': [4,5,10], 'min_samples_split': [20],'min_samples_leaf': [10], 'class_weight':['balanced']}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(criterion='entropy', max_depth=4, min_samples_leaf=10, min_samples_split=20)\n",
    "\n",
    "fpr2,tpr2=roc(model_tree,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB #or alternative NB implementations\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "print(\"f1_score: \", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"f1_test: \", f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(X_test) #predict_proba gives the probabilities for the target (0 and 1 in your case)\n",
    "\n",
    "fpr3,tpr3=roc(model,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "parameters = {\"C\":[1e-4,1e-3,1e-2,1e-1,1,10], \"max_iter\":[1000], 'class_weight':['balanced']}\n",
    "\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.0001, max_iter=1000, class_weight='balanced')\n",
    "\n",
    "fpr4,tpr4=roc(model,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "parameters = {\"kernel\":['linear', 'rbf'], \"C\":[0.1, 1], \"class_weight\":['balanced']}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SVC(C=0.1, kernel='rbf',probability=True, class_weight='balanced')\n",
    "\n",
    "fpr5,tpr5=roc(model,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron classifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "parameters = {\"hidden_layer_sizes\":[(10, 5),(20,5)],  \"max_iter\": [1000], \"alpha\": [0.001,0.1]}\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_MLP=MLPClassifier(hidden_layer_sizes=(20,5), alpha=0.1, max_iter=1000)\n",
    "\n",
    "fpr6,tpr6=roc(model_MLP,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(n_estimators=50, random_state=123)\n",
    "parameters={'criterion': ['entropy','gini'], 'max_depth': [4,5,10], 'min_samples_leaf': [5, 10],'min_samples_split': [5, 10]}\n",
    "\n",
    "def hyperp_search(classifier, parameters):\n",
    "    gs=GridSearchCV(classifier, parameters, cv=3, scoring = 'f1', verbose=0, n_jobs=-1)\n",
    "    gs=gs.fit(X_train, y_train)\n",
    "    print(\"f1_train: %f using %s\" %(gs.best_score_, gs.best_params_))\n",
    "\n",
    "    best_model=gs.best_estimator_\n",
    "    y_pred=best_model.predict(X_test)\n",
    "\n",
    "    print(\"f1_test: \", f1_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "hyperp_search(classifier,parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_RF=RandomForestClassifier(criterion='gini', max_depth=10, min_samples_leaf=5, min_samples_split=5)\n",
    "\n",
    "fpr7,tpr7=roc(model_RF,X_train,y_train,X_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr1, tpr1, label= \"KNN\")\n",
    "plt.plot(fpr2, tpr2, label= \"Tree\")\n",
    "plt.plot(fpr3, tpr3, label= \"NB\")\n",
    "plt.plot(fpr4, tpr4, label= \"Logistic\")\n",
    "plt.plot(fpr5, tpr5, label= \"SVM\")\n",
    "plt.plot(fpr6, tpr6, label= \"NeuralNet\")\n",
    "plt.plot(fpr7, tpr7, label= \"Random Forest\")\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Neural network - ok ma si può migliorare"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "X_train_tuner, X_val_tuner, y_train_tuner, y_val_tuner = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train, random_state=123)\n",
    "\n",
    "print(X_train_tuner.shape, X_val_tuner.shape)\n",
    "type(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes=2\n",
    "y_train_tuner_cat = to_categorical(y_train_tuner, num_classes)\n",
    "y_val_tuner_cat = to_categorical(y_val_tuner, num_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes)\n",
    "y_train_tuner_cat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sequential model \n",
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "   # model.add(layers.Input(None, 39))\n",
    "    # model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=128, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(2, activation=\"sigmoid\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"my_dir\",\n",
    "    project_name=\"helloworld\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner.search(X_train_tuner, y_train_tuner_cat, epochs=10, validation_data=(X_val_tuner, y_val_tuner_cat))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the top 2 models.\n",
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(None, 39))\n",
    "best_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((X_train_tuner, X_val_tuner))\n",
    "y_all = np.concatenate((y_train_tuner_cat, y_val_tuner_cat))\n",
    "\n",
    "x_all.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the top 2 hyperparameters.\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model = build_model(best_hps[0])\n",
    "\n",
    "#mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "\n",
    "history= model.fit(x=x_all, y=y_all, validation_split=0.33, epochs=300, batch_size=50, callbacks=[earlystopping])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "max_y_pred = np.argmax(y_pred, axis=1)\n",
    "max_y_pred\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, max_y_pred))\n",
    "print(\"Precision: \", precision_score(y_test,max_y_pred))\n",
    "print(\"Recall: \", recall_score(y_test, max_y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conmat = confusion_matrix(y_test, max_y_pred)\n",
    "val = np.mat(conmat) \n",
    "\n",
    "classnames = ['alive','dead']\n",
    "\n",
    "df_cm = pd.DataFrame(\n",
    "        val, index=classnames, columns=classnames, \n",
    "    )\n",
    "\n",
    "print(df_cm)\n",
    "\n",
    "plt.figure()\n",
    "heatmap = sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, max_y_pred)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-851f1b39",
   "language": "python",
   "display_name": "PyCharm (advancedSP)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}